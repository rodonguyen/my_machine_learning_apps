{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Twitter Spam Detection with LSTM Model\n",
    "# description: My first notebook shared on Mercury\n",
    "params:\n",
    "    tweet_content:\n",
    "        input: text\n",
    "        label: Tweet content\n",
    "        value: \"It's the everything else that's complicated. #PESummit #PXpic.twitter.com/Jsv6BA\"\n",
    "    year:\n",
    "        input: slider\n",
    "        label: Select year\n",
    "        value: 2022\n",
    "        min: 2021\n",
    "        max: 2030\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import utils, numpy, pandas, tensorflow, os, sys\n",
    "from tensorflow import keras\n",
    "# tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.modules.pop('utils')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweet_length = 106    # from training\n",
    "inputA = keras.layers.Input(shape = (max_tweet_length,1), name = 'tokenised_tweets')\n",
    "x = keras.layers.LSTM(128, return_sequences=True)(inputA)\n",
    "x = keras.layers.LSTM(64)(x)\n",
    "# x = LSTM(128)(inputA)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "\n",
    "inputB = keras.layers.Input(shape=(4,1), name='others')\n",
    "y = keras.layers.Flatten()(inputB)\n",
    "y = keras.layers.Dense(4, activation='relu')(y)\n",
    "\n",
    "combined = keras.layers.concatenate([x,y])\n",
    "output = keras.layers.Dense(32, activation='relu')(combined)\n",
    "output = keras.layers.Dropout(0.2)(output)\n",
    "output = keras.layers.Dense(1, activation='sigmoid')(output)\n",
    "lstm_model_2input = keras.models.Model([inputA, inputB], output)\n",
    "\n",
    "lstm_model_2input.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lstm_model_2input.load_weights(\"LSTM_model_02_969.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality examples\n",
    "# single_input = {'tweet': ['aaaaa trump win twitter cash'],'following': [100], 'followers': [200], 'actions': [33], 'is_retweet':[1] }\n",
    "single_input = {'tweet': [\"It's the everything else that's complicated. #PESummit #PXpic.twitter.com/Jsv6BAFQMl\"],'following': [0], 'followers': [11500], 'actions': [0], 'is_retweet':[0] }\n",
    "\n",
    "\n",
    "# Spam examples\n",
    "# single_input = {'tweet': ['EBMUD ending penalties for excessive water users https://t.co/D5a1FMVMHd'],'following': [4435], 'followers': [16000], 'actions': [27000], 'is_retweet':[0] }\n",
    "# single_input = {'tweet': ['aaaaaaaaaaaaaaaaaaaaa hell trump'],'following': [8221], 'followers': [4553], 'actions': [27858], 'is_retweet':[0] }\n",
    "\n",
    "\n",
    "columns_to_be_standardised = ['following', 'followers', 'actions']\n",
    "input_df = pandas.DataFrame(data=single_input)\n",
    "sigma, mu, tokenizer = utils.load_pickle('sigma_train.pkl'), utils.load_pickle('mu_train.pkl'), utils.load_pickle('tokeniser_train.pkl')\n",
    "\n",
    "# Process 'tweet'\n",
    "tweet_las, tweet_tokenised = utils.tokenise(input_df['tweet'], tokenizer)\n",
    "tweet_tensor = tensorflow.convert_to_tensor(tweet_tokenised)\n",
    "print(tweet_las)\n",
    "print(tweet_tokenised)\n",
    "print(tweet_tokenised.shape, tweet_tensor.shape)\n",
    "\n",
    "# Process 'following' 'followers' 'actions' 'is_retweet'\n",
    "others_col_std = utils.standardise(input_df, mu, sigma, columns_to_be_standardised)\n",
    "others_col_std.drop(['tweet'], axis=1, inplace=True)\n",
    "print(others_col_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "## Spam is 1, Not Spam is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lstm_model_2input.predict([tweet_tensor, others_col_std]) >= 0.5) * 1  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3543a095b31f9ef32d91d85f4f3f303d032d4ee8fe226d85fc4d24d71bd2d36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
